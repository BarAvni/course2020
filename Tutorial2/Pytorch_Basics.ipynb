{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Pytorch_Basics.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WeizmannML/course2020/blob/master/Tutorial2/Pytorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2TQSoSFmMMK",
        "colab_type": "text"
      },
      "source": [
        "### <font color=blue>Pytorch allows us to use automatic differentiation & use the power of GPU </font>\n",
        "#### All the code snippets in the following example are taken from https://pytorch.org/tutorials/beginner/pytorch_with_examples.html \n",
        "#### Other libraries like tensorflow or JAX allows us to do the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GkMHQccmMML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G5GPXd-mMMQ",
        "colab_type": "code",
        "outputId": "6b49dc6f-0b66-4663-f6b0-4a632c72b0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTs2LByDmMMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmJN6ylSmMMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----- for automatic detection of CPU vs GPU device ---------- #\n",
        "cuda_device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_zoJfb4mMMa",
        "colab_type": "text"
      },
      "source": [
        "#### The basic working objects are torch.Tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2vHUJQ1mMMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([[1., -1.], [1., -1.]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHoBQSERmMMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkUU6XufmMMh",
        "colab_type": "code",
        "outputId": "d2478b79-77df-4630-b34d-b22dd59a6b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(a), type(b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, torch.Tensor)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MriBZa40mMMl",
        "colab_type": "code",
        "outputId": "fbad6bc2-76b0-469b-a3a9-4c9b7b826568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBBvRwhHmMMo",
        "colab_type": "code",
        "outputId": "e11bc732-d5b7-4348-d262-f57b5ba4930b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double, device=cuda_device)      # new_* methods take in sizes\n",
        "print(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GUgfdRgmMMw",
        "colab_type": "code",
        "outputId": "89af788c-f88b-4b9e-ce6b-c3fb8d9f4f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.device ### equivalently can be done as x = x.to(cuda_device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0aJ-ru-mMM1",
        "colab_type": "code",
        "outputId": "3c35de38-07ef-4fb2-cfcd-13c04f337592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "x = torch.randn_like(x, dtype=torch.float64)    # override dtype!\n",
        "print(x) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.6352,  0.1964, -0.3800],\n",
            "        [ 0.3852,  0.2728,  1.4753],\n",
            "        [-0.4292,  0.3997,  0.1590],\n",
            "        [ 1.2749, -1.5792, -0.2541],\n",
            "        [-0.6466, -0.9019,  0.1966]], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC079UuBmMM5",
        "colab_type": "code",
        "outputId": "083acbd8-aa35-4fce-b815-24d83ca10a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(x.shape), print(x.size())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTBBkslqmMM7",
        "colab_type": "text"
      },
      "source": [
        "#### Conversion to numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3TE64AOmMM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wYD8povmMM-",
        "colab_type": "code",
        "outputId": "a28568fd-6511-4074-9166-376922873fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.63519641,  0.19636151, -0.38003401],\n",
              "       [ 0.38515931,  0.27277402,  1.47528017],\n",
              "       [-0.42920675,  0.39971346,  0.15899236],\n",
              "       [ 1.27492549, -1.57923226, -0.25406337],\n",
              "       [-0.64664443, -0.9019441 ,  0.19664337]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49A8u5AKmMNC",
        "colab_type": "code",
        "outputId": "31dddb1b-a3ac-453c-dac4-9537cdd5cce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.dtype"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTVzHrdbmMNE",
        "colab_type": "text"
      },
      "source": [
        "## The automatic differentiation of tensors through autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNohQYT6mMNF",
        "colab_type": "code",
        "outputId": "9e41573e-2e78-4f6e-b2ac-364b1efaeda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double, device=cuda_device)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.double, device=cuda_device, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3726,  0.6719,  1.0945],\n",
            "        [-2.2475,  0.4804,  0.2967],\n",
            "        [ 0.9076,  1.1119,  0.3307],\n",
            "        [-0.8365, -0.5879,  0.6081],\n",
            "        [-0.6809,  0.4516,  0.3228]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS-VQztZmMNH",
        "colab_type": "code",
        "outputId": "60908822-4da0-4117-a1bb-f7dd032b23f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "b = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]), dtype=torch.double, device=cuda_device, requires_grad=True)\n",
        "print(b)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6WYKymzmMNK",
        "colab_type": "code",
        "outputId": "09d1f694-61e9-4191-84e3-643f8c7cde38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.6274,  2.6719,  3.0945],\n",
            "        [-0.2475,  2.4804,  2.2967],\n",
            "        [ 2.9076,  3.1119,  2.3307],\n",
            "        [ 1.1635,  1.4121,  2.6081],\n",
            "        [ 1.3191,  2.4516,  2.3228]], device='cuda:0', dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvtAgyelmMNM",
        "colab_type": "code",
        "outputId": "0c5ae045-f1e4-4abd-ccfd-07ec0e322a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.grad_fn"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AddBackward0 at 0x7f3d62c7d780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGeApf-1mMNO",
        "colab_type": "code",
        "outputId": "8e8a6c07-c435-44bd-aa9f-0de290954c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "## -- assigning a required_grad criteria -- #\n",
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f3d62c8fa58>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DacMohwGmMNR",
        "colab_type": "code",
        "outputId": "035bf8a4-0193-4404-a346-1b0c417e3840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(a), print(b)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9263, 0.9252],\n",
            "        [1.4470, 7.7178]], requires_grad=True)\n",
            "tensor(63.3717, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z20Jm2HcmMNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv-0-5kEmMNV",
        "colab_type": "code",
        "outputId": "8f0b7e00-b2e2-4633-e2c6-0ad2a88c6e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([684.5993, 966.2435, 875.7535], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUqo4W0fmMNX",
        "colab_type": "code",
        "outputId": "944f4ed7-470b-4002-f0aa-77f8d246a7fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6686, 0.9436, 0.8552], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfbWmbxlmMNZ",
        "colab_type": "code",
        "outputId": "c423610c-7714-455c-b7da-3c35374e3d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDsm-3h8mMNb",
        "colab_type": "text"
      },
      "source": [
        "### Doing a backpropagation in the numpy way with torch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-yHMQSPmMNc",
        "colab_type": "code",
        "outputId": "59de32a5-5bcc-4d1d-910a-5d52249be421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "\n",
        "dtype = torch.float\n",
        "device = cuda_device\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.mm(w1)\n",
        "    h_relu = h.clamp(min=0) # -- the clamp filters out < 0 values\n",
        "    y_pred = h_relu.mm(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 50 == 49:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
        "    grad_h = grad_h_relu.clone()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.t().mm(grad_h) # -- we had x.T for numpy arrays\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 14719.201171875\n",
            "99 644.8609008789062\n",
            "149 46.995662689208984\n",
            "199 4.073708534240723\n",
            "249 0.38698551058769226\n",
            "299 0.03881172463297844\n",
            "349 0.004271837882697582\n",
            "399 0.0006967298686504364\n",
            "449 0.00018994123092852533\n",
            "499 7.616233051521704e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPtVm9cMmMNe",
        "colab_type": "text"
      },
      "source": [
        "## Using the autograd function of pytorch to compute the derivatives & do backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlDeqMZjmMNe",
        "colab_type": "code",
        "outputId": "8aff22b3-325f-4f2f-cc1c-a55bfa03db68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "dtype = torch.float\n",
        "device = cuda_device\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold input and outputs.\n",
        "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
        "# with respect to these Tensors during the backward pass.\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "# Create random Tensors for weights.\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y using operations on Tensors; these\n",
        "    # are exactly the same operations we used to compute the forward pass using\n",
        "    # Tensors, but we do not need to keep references to intermediate values since\n",
        "    # we are not implementing the backward pass by hand.\n",
        "    y_pred = x.mm(w1).clamp(min=0).mm(w2) # --- the forward pass through two layers is happening here.\n",
        "\n",
        "    # Compute and print loss using operations on Tensors.\n",
        "    # Now loss is a Tensor of shape (1,)\n",
        "    # loss.item() gets the scalar value held in the loss.\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 50 == 49:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass. This call will compute the\n",
        "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
        "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
        "    # of the loss with respect to w1 and w2 respectively.\n",
        "    loss.backward()\n",
        "\n",
        "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
        "    # because weights have requires_grad=True, but we don't need to track this\n",
        "    # in autograd.\n",
        "    # An alternative way is to operate on weight.data and weight.grad.data.\n",
        "    # Recall that tensor.data gives a tensor that shares the storage with\n",
        "    # tensor, but doesn't track history.\n",
        "    # You can also use torch.optim.SGD to achieve this.\n",
        "    with torch.no_grad():\n",
        "        w1 -= learning_rate * w1.grad\n",
        "        w2 -= learning_rate * w2.grad\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        w1.grad.zero_()\n",
        "        w2.grad.zero_()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 18706.25\n",
            "99 1044.6990966796875\n",
            "149 99.78321838378906\n",
            "199 11.367023468017578\n",
            "249 1.4026386737823486\n",
            "299 0.18116317689418793\n",
            "349 0.024268273264169693\n",
            "399 0.003602081909775734\n",
            "449 0.0007400322938337922\n",
            "499 0.0002270481490995735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9cnANo6mMNi",
        "colab_type": "text"
      },
      "source": [
        "### The PyTorch nn Modeule, contains the basic NN layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BAFwuDkmMNi",
        "colab_type": "code",
        "outputId": "4bf004a6-062c-45ed-8182-30b5718811b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "    # override the __call__ operator so you can call them like functions. When\n",
        "    # doing so you pass a Tensor of input data to the Module and it produces\n",
        "    # a Tensor of output data.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 50 == 49:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 36.841087341308594\n",
            "99 3.06765079498291\n",
            "149 0.3778367340564728\n",
            "199 0.05494300276041031\n",
            "249 0.00927006546407938\n",
            "299 0.001778186997398734\n",
            "349 0.00037723430432379246\n",
            "399 8.689654350746423e-05\n",
            "449 2.1427822503028437e-05\n",
            "499 5.600826625595801e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeWbwb2omMNl",
        "colab_type": "text"
      },
      "source": [
        "### Updating the weights through PyTorch optim "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc375LWxmMNl",
        "colab_type": "code",
        "outputId": "43e789ca-837b-4381-e212-46a06c23c7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# Use the nn package to define our model and loss function.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use Adam; the optim package contains many other\n",
        "# optimization algoriths. The first argument to the Adam constructor tells the\n",
        "# optimizer which Tensors it should update.\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y by passing x to the model.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 50 == 49:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable\n",
        "    # weights of the model). This is because by default, gradients are\n",
        "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 213.7782440185547\n",
            "99 51.5125617980957\n",
            "149 7.841900825500488\n",
            "199 0.7790022492408752\n",
            "249 0.05822024121880531\n",
            "299 0.003562858561053872\n",
            "349 0.00018537286086939275\n",
            "399 7.69027610658668e-06\n",
            "449 2.302582373658879e-07\n",
            "499 4.73958117197526e-09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVGtoNcMmMNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzpAQSh-qXBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}