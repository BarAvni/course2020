{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot( [1,2], [1, 2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a 2-feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create the point that we are going to use for the classifier.\n",
    "# We create n_points points for four classes of points center at [0,0], \n",
    "# [0,2], [2,0] and [2,2] with a deviation from the center that follows a\n",
    "# Gaussian distribution with a standar deviation of sigma.\n",
    "\n",
    "n_points = 20000\n",
    "points = np.zeros((n_points,2))   # x, y\n",
    "target = np.zeros((n_points,1))   # label\n",
    "sigma = 0.5\n",
    "for k in range(n_points):\n",
    "    # Random selection of one class with 25% of probability per class.\n",
    "    random = np.random.rand()\n",
    "    if random<0.25:\n",
    "        center = np.array([0,0])\n",
    "        target[k,0] = 0   # This points are labeled 0.\n",
    "    elif random<0.5:\n",
    "        center = np.array([2,2])\n",
    "        target[k,0] = 1   # This points are labeled 1.\n",
    "    elif random<0.75:\n",
    "        center = np.array([2,0])\n",
    "        target[k,0] = 2   # This points are labeled 2.\n",
    "    else:\n",
    "        center = np.array([0,2])\n",
    "        target[k,0] = 3   # This points are labeled 3.\n",
    "    gaussian01_2d = np.random.randn(1,2)\n",
    "    points[k,:] = center + sigma*gaussian01_2d\n",
    "\n",
    "# Now, we write all the points in a file.\n",
    "points_and_labels = np.concatenate((points,target),axis=1)   # 1st, 2nd, 3nd column --> x,y, label\n",
    "pd.DataFrame(points_and_labels).to_csv('clas.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom dataset builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the dataset and create an iterable.\n",
    "class my_points(data.Dataset):\n",
    "    def __init__(self, filename):\n",
    "        pd_data = pd.read_csv(filename).values   # Read data file.\n",
    "        self.data = pd_data[:,0:2]   # 1st and 2nd columns --> x,y\n",
    "        self.target = pd_data[:,2:]  # 3rd column --> label\n",
    "        self.n_samples = self.data.shape[0]\n",
    "    \n",
    "    def __len__(self):   # Length of the dataset.\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
    "        return torch.Tensor(self.data[index]), torch.Tensor(self.target[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- use the custom dataset builder to read the saved file --- #\n",
    "my_data = my_points('clas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = my_data.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6990, 1.8946]), tensor([3.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 200\n",
    "my_loader = data.DataLoader(my_data,batch_size=batch_size,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build a simple model with the inputs and one output layer.\n",
    "class my_model(nn.Module):\n",
    "    def __init__(self,n_in=2,n_hidden=5,n_out=4):\n",
    "        super(my_model,self).__init__()\n",
    "        self.n_in  = n_in\n",
    "        self.n_out = n_out\n",
    "        self.n_hidden = n_hidden\n",
    "         \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.n_in, self.n_hidden),\n",
    "            nn.Linear(self.n_hidden ,self.n_hidden),   # Hidden layer.\n",
    "            nn.Linear(self.n_hidden ,self.n_out)\n",
    "            )\n",
    "        self.logprob = nn.LogSoftmax(dim=1)                 # -Log(Softmax probability).\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "        x = self.logprob(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we create the mode, the loss function or criterium and the optimizer \n",
    "# that we are going to use to minimize the loss.\n",
    "\n",
    "# Model.\n",
    "model = my_model()\n",
    "\n",
    "# Negative log likelihood loss.\n",
    "criterium = nn.NLLLoss()\n",
    "\n",
    "# Adam optimizer with learning rate 0.1 and L2 regularization with weight 1e-4.\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.1,weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.4183 at iter 0\n",
      "Loss 0.2834 at iter 10\n",
      "Loss 0.1247 at iter 20\n",
      "Loss 0.2479 at iter 30\n",
      "Loss 0.1875 at iter 40\n",
      "Loss 0.2161 at iter 50\n",
      "Loss 0.1314 at iter 60\n",
      "Loss 0.1637 at iter 70\n",
      "Loss 0.1554 at iter 80\n",
      "Loss 0.1234 at iter 90\n"
     ]
    }
   ],
   "source": [
    "loss_array = []\n",
    "epoch = 0\n",
    "\n",
    "# Taining.\n",
    "for k, (data, target) in enumerate(my_loader):\n",
    "    # Definition of inputs as variables for the net.\n",
    "    # requires_grad is set False because we do not need to compute the \n",
    "    # derivative of the inputs.\n",
    "    data   = Variable(data,requires_grad=False)\n",
    "    target = Variable(target.long(),requires_grad=False)\n",
    "    \n",
    "    # Set gradient to 0.\n",
    "    optimizer.zero_grad()\n",
    "    # Feed forward.\n",
    "    pred = model(data)\n",
    "    # Loss calculation.\n",
    "    loss = criterium(pred,target.view(-1))\n",
    "    \n",
    "    loss_array.append(loss.item() )\n",
    "    # Gradient calculation.\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    # Print loss every 10 iterations.\n",
    "    if k%10==0:\n",
    "        print('Loss {:.4f} at iter {:d}'.format(loss.item(),k))\n",
    "        \n",
    "    # Model weight modification based on the optimizer. \n",
    "    optimizer.step()\n",
    "    \n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4183398485183716,\n",
       " 1.0551203489303589,\n",
       " 0.8563979864120483,\n",
       " 0.6573379039764404,\n",
       " 0.6745700240135193,\n",
       " 0.4987020790576935,\n",
       " 0.5096487998962402,\n",
       " 0.5261693596839905,\n",
       " 0.4846927225589752,\n",
       " 0.33853232860565186,\n",
       " 0.2834238111972809,\n",
       " 0.22796188294887543,\n",
       " 0.24100318551063538,\n",
       " 0.18968617916107178,\n",
       " 0.2606349587440491,\n",
       " 0.16507971286773682,\n",
       " 0.14063751697540283,\n",
       " 0.13386119902133942,\n",
       " 0.12387032806873322,\n",
       " 0.16052421927452087,\n",
       " 0.12470211833715439,\n",
       " 0.156971275806427,\n",
       " 0.23425281047821045,\n",
       " 0.11944937705993652,\n",
       " 0.071257084608078,\n",
       " 0.09811783581972122,\n",
       " 0.13698934018611908,\n",
       " 0.1221332848072052,\n",
       " 0.06319287419319153,\n",
       " 0.11022818833589554,\n",
       " 0.2478848695755005,\n",
       " 0.11797653138637543,\n",
       " 0.20196819305419922,\n",
       " 0.17308355867862701,\n",
       " 0.16037531197071075,\n",
       " 0.23847422003746033,\n",
       " 0.17764964699745178,\n",
       " 0.1549004316329956,\n",
       " 0.210675448179245,\n",
       " 0.16311874985694885,\n",
       " 0.1874532252550125,\n",
       " 0.1316392570734024,\n",
       " 0.1622990071773529,\n",
       " 0.19704896211624146,\n",
       " 0.21944347023963928,\n",
       " 0.14088526368141174,\n",
       " 0.1115894541144371,\n",
       " 0.17749622464179993,\n",
       " 0.09515982866287231,\n",
       " 0.1920253187417984,\n",
       " 0.21605435013771057,\n",
       " 0.08768483996391296,\n",
       " 0.1072094663977623,\n",
       " 0.20398278534412384,\n",
       " 0.08238314837217331,\n",
       " 0.07399481534957886,\n",
       " 0.19588080048561096,\n",
       " 0.07046647369861603,\n",
       " 0.160685732960701,\n",
       " 0.16409184038639069,\n",
       " 0.13137280941009521,\n",
       " 0.14224585890769958,\n",
       " 0.19125007092952728,\n",
       " 0.1633758693933487,\n",
       " 0.19121937453746796,\n",
       " 0.18817131221294403,\n",
       " 0.06609048694372177,\n",
       " 0.17770493030548096,\n",
       " 0.11833546310663223,\n",
       " 0.08069339394569397,\n",
       " 0.16372035443782806,\n",
       " 0.10028548538684845,\n",
       " 0.08409979194402695,\n",
       " 0.16707541048526764,\n",
       " 0.1701490581035614,\n",
       " 0.1933251917362213,\n",
       " 0.17753076553344727,\n",
       " 0.1320171356201172,\n",
       " 0.13934919238090515,\n",
       " 0.1428515762090683,\n",
       " 0.155410498380661,\n",
       " 0.13522128760814667,\n",
       " 0.18497887253761292,\n",
       " 0.17532643675804138,\n",
       " 0.19428633153438568,\n",
       " 0.10386547446250916,\n",
       " 0.11911238729953766,\n",
       " 0.12218387424945831,\n",
       " 0.14834000170230865,\n",
       " 0.18212933838367462,\n",
       " 0.12335340678691864,\n",
       " 0.13030371069908142,\n",
       " 0.11912787705659866,\n",
       " 0.09203547239303589,\n",
       " 0.1429005116224289,\n",
       " 0.1461922973394394,\n",
       " 0.18144826591014862,\n",
       " 0.0952085554599762,\n",
       " 0.0625835657119751,\n",
       " 0.17855216562747955]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now, we plot the results.\n",
    "# # Circles indicate the ground truth and the squares are the predictions.\n",
    "\n",
    "# colors = ['r','b','g','y']\n",
    "# points = data.numpy()\n",
    "\n",
    "# print('Reached here')\n",
    "\n",
    "# # Ground truth.\n",
    "# target = target.numpy()\n",
    "# for k in range(4):\n",
    "#     select = target[:,0]==k\n",
    "#     p = points[select,:]\n",
    "#     plt.scatter(p[:,0],p[:,1],facecolors=colors[k])\n",
    "\n",
    "# # Predictions.\n",
    "# pred = pred.exp().detach()     # exp of the log prob = probability.\n",
    "# _, index = torch.max(pred,1)   # index of the class with maximum probability.\n",
    "# pred = pred.numpy()\n",
    "# index = index.numpy()\n",
    "# for k in range(4):\n",
    "#     select = index==k\n",
    "#     p = points[select,:]\n",
    "#     plt.scatter(p[:,0],p[:,1],s=60,marker='s',edgecolors=colors[k],facecolors='none')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
